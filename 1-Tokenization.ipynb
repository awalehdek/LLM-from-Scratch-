{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa873a4-2d25-48d2-8096-0efc93eaee16",
   "metadata": {},
   "source": [
    "# Create Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99648962-cc52-4239-9975-1d19a7ba474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f87e66-f7f2-4731-a93b-8622311b8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "# Open in binary mode\n",
    "with open(\"The_Verdict.pdf\", \"rb\") as fp:\n",
    "    reader = PyPDF2.PdfReader(fp)\n",
    "    text_book = \"\"\n",
    "    for page in reader.pages:\n",
    "        text_book += page.extract_text() or \"\"  # Avoid None\n",
    "\n",
    "print(\"Total number of characters:\", len(text_book))\n",
    "print(text_book[:999])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4559df-768b-4ff0-9c71-14a94796a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "text1  = \"Today is sunny, let's -- go to the beach!\"\n",
    "# split text around empty space\n",
    "res = re.split(r'\\s', text1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fec4c2-97f7-4b6c-9d4e-247fb15ba94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text around empty space, comman and period\n",
    "res = re.split(r'[,.]|\\s', text1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b31bd-cbfb-4e44-bff2-102a905ad07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = re.split(r'([,.:?!\",()]|--|\\s)', text1)\n",
    "\n",
    "# Removing white spaces\n",
    "res = [word for word in res if word.strip() ]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9844461-650e-4080-8ffe-01b16e0b2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize by removing all space, comma, --, etcc\n",
    "res = [word.strip() for word in res if word.strip() ]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfff15f-b80e-4d67-8ffd-54e6436d55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing \n",
    "preprocess = re.split(r'( [,.:?!\",()]|--|\\s)', text_book)\n",
    "preprocess = [word.strip() for word in preprocess if word.strip() ]\n",
    "print(preprocess[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb542d0-2630-421d-94ac-f54da2e29812",
   "metadata": {},
   "source": [
    "# get the unique word vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f6fea-efe6-4164-be18-12a84afaf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "w = sorted(set(preprocess))\n",
    "vocabulary = {key: value for key, value in enumerate(w)}\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb157a-2620-49e0-aa1e-239c9a49aba5",
   "metadata": {},
   "source": [
    "# Encode and Decode \n",
    "1. Simple Text (Raw Input):   \"Hello, world!\"\n",
    "2. Tokenized Text (Splitting into Tokens):\n",
    "\n",
    "               A- Whole words (\"Hello\", \"world\")\n",
    "               B- Subwords (\"unhappiness\" → \"un\", \"happiness\")\n",
    "               C- Punctuation and symbols (\",\", \"!\")\n",
    "               Tokenized Output: [\"Hello\", \",\", \"world\", \"!\"]\n",
    "3. Token IDs (Numerical Representation):\n",
    "\n",
    "                \"Hello\" → 15496\n",
    "                \",\" → 11\n",
    "                \"world\" → 995\n",
    "                \"!\" → 0\n",
    "                Final Token IDs: [15496, 11, 995, 0]\n",
    "4. Decode is the reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4406e-8c9c-4a35-9371-b76a749caa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenization:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.string_to_int = vocabulary\n",
    "        self.int_to_string = {item: s for s,item in vocabulary.items()}\n",
    "\n",
    "    def encoding(self, text):\n",
    "        # split text around empty space, comman and period\n",
    "        preprocessing = re.split(r'([,.:?!\",()]|--|\\s)', text1)\n",
    "        # Tokenize by removing all space, comma, --, etcc\n",
    "        preprocessing = [word.strip() for word in preprocessing if word.strip() ]\n",
    "        # converting into id number\n",
    "        id = [self.string_to_int[s] for s in preprocessing ]\n",
    "        return id "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
